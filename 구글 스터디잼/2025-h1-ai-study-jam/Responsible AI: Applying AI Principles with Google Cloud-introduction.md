# Google Cloud로 AI 원칙 적용하기: 책임감 있는 AI 실천

-   **과정 소개**: 책임감 있는 AI(Responsible AI)의 실천에 중점을 둔 과정
-   **주요 내용**: Google Cloud의 책임감 있는 AI 개발 및 사용 여정 공유, 조직의 AI 전략 수립 지원

## AI의 현재와 발전

-   **일상 속 AI**: 교통/날씨 예측, 콘텐츠 추천 등 이미 일상적인 상호작용
-   **생성형 AI의 부상**: AI 미적용 기술이 부족하게 느껴질 수 있음
-   **접근성 향상**: 과거 전문가(소수 엔지니어) 영역이었으나, 진입 장벽 낮아져 비전문가도 AI 구축 가능
-   **AI 능력**: 컴퓨터가 세상을 보고, 이해하고, 상호작용하는 방식이 크게 발전
-   **발전 속도 (Stanford AI Index 2019)**:
    -   ~2012년: 컴퓨팅 성능 2년마다 2배 증가 (무어의 법칙)
    -   2012년 이후: 컴퓨팅 성능 약 3.5개월마다 2배 증가
-   **성능 향상 예시 (ImageNet 이미지 분류)**:
    -   2011년 오류율: 26%
    -   2020년 오류율: 2% (참고: 사람 오류율 5%)

## 책임감 있는 AI의 필요성

-   **AI의 한계**: 놀라운 발전에도 불구하고 AI는 완벽하지 않음 (오류 가능성 존재)
-   **문제 인식**: 책임감 있는 AI 개발을 위해 가능한 이슈, 한계, 의도치 않은 결과 이해 필요
-   **사회 반영**: 기술은 사회를 반영하므로, 좋은 관행 없이는 AI가 기존 문제/편견을 복제하고 증폭시킬 수 있음
-   **정의의 부재**:
    -   '책임감 있는 AI'에 대한 보편적 정의 없음
    -   구현을 위한 단순 체크리스트나 공식 없음
-   **조직별 원칙**: 각 조직은 미션과 가치를 반영한 자체 AI 원칙 개발
-   **공통 주제**: 투명성(Transparency), 공정성(Fairness), 책임성(Accountability), 개인 정보 보호(Privacy)

## Google의 책임감 있는 AI 접근 방식

-   **Google의 약속**: 모든 사람을 위한 AI, 책임감 있고 안전하며, 개인 정보 존중, 과학적 우수성 기반 AI 추구
-   **Google의 노력**:
    -   자체 AI 원칙, 관행, 거버넌스 프로세스, 도구 개발
    -   제품 및 조직에 '책임감을 고려한 설계(Responsibility by Design)' 통합
    -   AI 원칙을 책임감 있는 의사 결정 프레임워크로 활용
-   **지속적인 노력**:
    -   Google이 모든 해답을 가진 것은 아님
    -   지속적인 학습과 개선 추구
    -   배운 점을 공유하고 협력하여 다른 이들의 여정 지원 목표

## 과정의 목표 및 AI 용어 설명

-   **모두의 역할**: 설계, 배포, 적용 등 AI 프로세스 모든 단계에서 각자의 역할과 책임 중요
-   **결정의 영향**: 모든 결정은 영향을 미치므로, 정의되고 반복 가능한 책임감 있는 AI 사용 프로세스 필요
-   **Google의 기여**: 사회적 가치 기술 구축 + 책임감 있는 관행 장려 (통찰력 및 교훈 공유)
-   **과정 목표**: Google/Google Cloud의 책임감 있는 AI 여정 공유, 수강생의 조직 전략 수립 지원
-   **AI 용어 (AI, ML, Deep Learning)**:
    -   보편적으로 합의된 정의 부재
    -   정의 부재가 기술 발전을 막지는 못함 -> 책임감 있는 개발/사용 논의 중요
    -   Google: AI 원칙 적용 대상을 포괄하는 '첨단 기술 개발(Advanced Technology Development)' 용어 사용
    -   **핵심**: 용어 정의보다 **책임감 있는 기술 개발**에 집중

## AI 개발에서 인간의 역할 강조

-   **흔한 오해**: 기계가 핵심 의사 결정자라는 인식
-   **현실**: **사람**이 기계를 설계, 구축하고 사용 방식 결정
-   **인간의 개입**:
    -   학습 데이터 수집/생성
    -   AI 배포 및 적용 방식 통제
-   **가치 내재**: 모든 기술 제품에는 인간의 결정(가치관 기반)이 스며있음
    -   예: 특정 문제 해결에 생성형 AI 사용 결정, ML 수명 주기 전반의 결정 등
-   **결론**: 개념 구상부터 배포, 유지보수까지 모든 결정 지점에서 책임감 있는 고려와 평가 필수
