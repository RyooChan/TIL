# study013
###### tags: `Tag(가상 면접 사례로 배우는 대규모 시스템 설계 기초)`

## 검색어 자동완성 시스템

검색창에서의 자동완성과 같은 내용을 출력하는 방법을 알아본다.

### 1단계 문제 이해 및 설계 범위 확정

* 사용자가 입력하는 단어는 자동완성될 검색어의 첫부분에 한정한다.
* 5개의 자동완성 검색어를 표시한다.
    * 해당 기준은 질의 빈도에 따라 정해지는 검색어 인기 순위를 기준으로 삼는다.
* 맞춤법 검사나 자동수정은 지원하지 않는다.
* 질의는 영어를 기본으로, 다국어도 시간이 허락되면 지원해도 된다.
    * 모든 질의는 소문자를 기준으로 한다.
* 10million(천만명) 의 DAU(일간 능동 사용자) 를 갖는다.

---

이 요구사항을 정리하면 다음과 같다.
* 빠른 응답속도
    * 페이스북 검색어 자동완성 시스템에 관한 문서를 보면 시스템 응답속도는 100밀리초 이내여야 한다.
* 연관성
    * 자동완성되어 출력되는 검색어는 사용자가 입력한 단어와 연관된 것이어야 한다.
* 정렬
    * 계산 결과는 인기도 등의 순위 모델에 의해 정렬되어 있어야 한다.
* 규모 확장성
    * 시스템은 많은 트래픽을 감당할 수 있도록 확장 가능해야 한다.
* 고가용성

---

개략적 규모 추정
* DAU는 천만명으로 가정한다.
* 평균적으로 한 사용자는 매일 10건의 검색을 수행한다고 가정한다.
* 한번의 질의에 평균 20바이트의 데이터를 입력한다고 가정한다.
    * ASCII를 사용해서 인코딩한다. -> 1문자는 1바이트
    * 질의문은 평균 4단어로 이루어진다고 가정할것이며, 각 단어는 평균 다섯글자로 구성된다고 가정한다.
        * 즉 질의당 평균 4X5 = 20바이트이다.
* 글자를 입력할 때마다 검색어 자동완성 백엔드에 요청을 보낸다.
    * 즉 평균 1회 검색당 20회의 요청이 백엔드로 전달된다.
        * 대략 초당 24000건의 질의가 발생한다. -> 10000000(사용자)X10질의X20자/24/3600초
            * 최대 QPS = QPSX2 = 대략 48000
* 질의 가운데 20%정도는 신규 검색어라고 가정한다. 따라서 대략 0.4GB정도의 신규 데이터가 시스템에 추가된다.

### 2단계 개략적 설계안 제시 및 동의 구하기

개략적으로 시스템은 두 부분으로 나뉜다.
1. 데이터 수집 서비스
사용자가 입력한 질의를 실시간으로 수집하는 시스템이다.
데이터가 많은 애플리케이션에 실시간 시스템은 그다지 바람직하지 않지만 설계안을 만드는 출발점으로는 괜찮을 것이다.
이후 상세 설계안을 준비할때 보다 현실적인 안으로 교체한다.
2. 질의 서비스
주어진 질의에 다섯 개의 인기 검색어를 정렬해 내놓는 서비스이다.

#### 데이터 수집 서비스

질의 - 빈도 를 저장하는 테이블이 있고, 이 테이블이 검색에 따라 이런 식으로 값이 갱신된다.

![](https://i.imgur.com/ff2gXMR.png)

#### 질의 서비스

![](https://i.imgur.com/XBJYW3P.png)

이 테이블을 보면 두 개의 필드가 있는데
* query
    * 질의문 저장
* frequency
    * 질의문 사용 빈도 저장

이제 여기서 사용자가 "tw"를 입력하면 아래의 top 자동완성 검색어가 표시된다.

![](https://i.imgur.com/hLr4ac5.png)

![](https://i.imgur.com/keuZxWY.png)

이 방식은 데이타 양이 적을 때는 나쁘지 않지만, 데이터가 많아지면 DB 병목현상이 일어날 수 있다. 상세 설계안에서 이 문제를 해결한다.

### 3단계 상세 설계

위의 개략적 설계에서 컴포넌트를 몇 개 골라 상세히 설계하고 다음 순서로 최적화 방안을 논의한다.

* 트라이(trie) 자료구조
* 데이터 수집 서비스
* 질의 서비스
* 규모 확장이 가능한 저장소
* 트라이 연산

#### 트라이 자료구조

개략적 설계안에서는 관계형 DB를 저장소로 사용했는데, 이 때의 비효율적 문제를 트라이를 사용해 해결한다.
이 트라이(trie)가 시스템의 핵심적 부분이 될 것이므로 요구사항에 딱 맞는 트라이를 만들도록 한다.

먼저 트라이는 문자열을 간략하게 저장할 수 있느 자료구조이다.
트라이라는 이름은 retrieval이라는 단어에서 온 것인데, 문자열을 꺼내는 연산에 초점을 맞추어 설계된 자료구조이다.
이 트라이 자료구조의 핵심 아이디어는 다음과 같다.

* 트리 형태의 자료구조
* 루트 노드는 빈 문자열을 나타낸다.
* 각 노드는 character하나를 저장하며, 26개의 자식 노드를 가질 수 있다.
* 각 트리 노드는 하나의 단어 혹은 접두어 문자열(prefix string)을 나타낸다.

![](https://i.imgur.com/jTyO5SI.png)

'tree', 'try', 'true', 'toy', 'wish', 'win'이 보관된 트라이가 있다면 기본 트라이 자료구조는 노드에 문자들을 저장한다.

이용 빈도에 따라 정렬된 결과를 내놓기 위해서는 노드에 빈도 정보까지 저장할 필요가 있다.

![](https://i.imgur.com/0E0Z2EB.png)

이런 빈도 테이블이 있다고 칠 때 이 빈도 정보를 트라이 노드에 저장하면

![](https://i.imgur.com/HkGWS3b.png)

이렇게 된다.

먼저 트라이의 용어 몇 가지가 있는데

* p 
    * 접두어(prefix)의 길이
* n
    * 트라이 안에 있는 노드 개수
* c
    * 주어진 노드의 자식 노드 개수

그러면 이 트라이를 통해 자동완성을 구현한다고 생각하면 가장 많이 사용된 질의어 k는 다음과 같이 찾을 수 있다.

* 해당 접두어를 표현하는 노드를 찾는다.
    * 시간 복잡도는 O(p)이다.
        * 문자열 집합의 개수와 상관 없이, 찾고자 하는 문자열의 길이가 시간 복잡도가 된다.
            * 해당 접두어 즉 prefix를 찾아가는 데에 p만큼의 검색을 진행해서 시간복잡도가 O(p)라고 한다.
* 해당 노드부터 시작하는 하위 트리를 탐색하여 모든 유효 노드를 찾는다. 유효한 검색 문자열을 구성하는 노드가 유효 노드다. 
    * 시간 복잡도는 O(c)이다.
        * O(1) * C인감??
* 유효 노드들을 정렬하여 가장 인기있는 검색어 k개를 찾는다.
    * 시간 복잡도는 O(clogc)이다.
        * 트라이는 배열을 반씩 분할해가면서 하는거라서.. 혹시 병합정렬이라서 clogc인가???

이제 k=2이고 사용자가 'be'를 입력했다고 하면 알고리즘 동작은 다음과 같다.

1. 접두어 노드 'be'를 찾는다.
2. 해당 노드부터 시작하는 하위 트리를 탐색하여 모든 유효 노드를 찾는다.
아래 그림에서는 [beer:10], [best:35], [bet:29]이다.
3. 유효 노드를 정렬하여 2개만 골라낸다.
[best:35]와 [bet:29]가 접두어 'tr'에 대해 검색된 2개의 인기 검색어다. -> 'be' 오타일것같은데

![](https://i.imgur.com/nGtzrBO.png)

여기서 소요된 시간은
O( p) + O( c) + O(clogc)

이 알고리즘은 직관적이지만 최악의 경우는 k개의 결과를 위해 전체 트라이를 모두 검색해야 할수도 있다.
이를 해결하기 위해서는 두 가지가 제안되는데

1. 접두어의 최대 길이를 제한
2. 각 노드에 인기 검색어를 캐시

이다.

#### 접두어 최대 길이 제한

사용자가 검색창에 긴 검색어를 입력하는 일은 거의 없기 떄문에 p값은 작은 정수값으로 가정해도 된다.
이렇게 검색어의 최대 길이를 제한할 수 있다면 O(p)의 값은 작은 정수가 되므로 O(1)로 생각 가능하다(작은 상수이므로)

#### 노드에 인기 검색어 캐시

각 노드에 k개의 인기 검색어를 저장해 두면 전체 트라이를 검색하는 일을 방지할 수 있다. 5~10개 정도의 자동완성 제안을 표시하면 충분하므로 k는 작은 값이다.
여기서는 5개의 질의를 캐시한다고 한다.
각 노드에 이렇게 인기 질의어를 캐시하면 'top5'검색어를 질의하는 시간복잡도를 엄청나게 낮출 수 있다.
하지만 각 노드에 질의어를 저장할 공간이 많이 필요하게 된다는 단점도 있다.
빠른 응답속도가 아주 중요할 때는 이정도 저장공간을 희생할 가치는 있다.

![](https://i.imgur.com/xWjcrVx.png)

개선된 트라이 구조다.
각 노드에 가장 인기있는 검색어 다섯가지를 저장하도록 했다.
예를 들어 접두어 be를 나타내는 노드에는
[best:35, bet:29, bee:20, be:15, beer:10]의 다섯개 검색어를 캐시해 두었다.

---

위의 2가지 최적화 기법을 사용하면 시간 복잡도는

접두어 노드를 찾는 시간 복잡도 -> O(1)
최고 인기 검색어 5개를 찾는 질의 시간 복잡도 -> O(1)이 된다.

그래서 최고 인기 검색어 k개를 찾는 전체 알고리즘의 복잡도도 O(1)로 바뀌게 된다.

---

### 데이터 수집 서비스

지금까지는 사용자가 검색창에 타이핑을 할 때마다 실시간으로 데이터를 수정했는데, 이 방법은 두 가지 문제로 실용적이지 못하다.

* 매일 수천만건의 질의가 입력될 텐데 그때마다 트라이 갱신을 하는 경우 속도가 느려진다.
* 인기 있는 검색어는 그다지 잘 안바뀌니까 트라이를 그리 자주 갱신할 필요는 없다.

그러니까 우리는 검색을 하는 사이트를 위한 내용을 찾기 때문에 자주 바꿀 필요는 없고, 그 수정된 설계안은 다음과 같다.

![](https://i.imgur.com/E3J9tDf.png)

##### 데이터 분석 서비스 로그

데이터 분석 서비스 로그에는 검색창에 입력된 질의에 관한 원본 데이터가 보관된다.
새로운 데이터가 추가될 뿐 수정은 이루어지지 않으며 로그 데이터에는 인덱스를 걸지 않는다.

![](https://i.imgur.com/HZA1JnZ.png)

##### 로그 취합 서버

데이터 분석 서비스로부터 나오는 로그는 양이 엄청나고 데이터 형식도 제각각인 경우가 많다.
따라서 이 데이터를 잘 취합하여(aggregation) 우리 시스템이 쉽게 소비할 수 있도록 해야 한다.
여기서는 일단 일주일 주기로 취합한다고 가정한다.

-> batch를 사용해서 취합하는게 맞을까?

##### 취합된 데이터

![](https://i.imgur.com/y61OM82.png)

그렇게 취합한 데이터의 사례이다.
time필드는 해당 주가 시작한 날짜를 나타낸다.

##### 작업 서버

작업 서버는 주기적으로 비동기적 작업(job)을 실행하는 서버 집합이다.
트라이 자료구조를 만들고 트라이 DB에 저장하는 역할을 담당한다.

-> 아마 job이 있는걸로 봐서는 이쪽이 batch인것 같다!

##### 트라이 캐시

분산 캐시 시스템으로, 트라이 데이터를 메모리에 유지하여 읽기 연산 성능을 높이는 구실을 한다.
매주 트라이 DB의 스냅샷을 떠서 갱신한다.

##### 트라이 DB

지속성 저장소이다.
이 트라이 저장소로 쓸 수 있는 선택지로는 두 가지가 있다.

* 문서 저장소
    * 새 트라이를 매주 만들 것이므로, 주기적으로 트라이를 직렬화하여 DB에 저장할 수 있다. mongoDB같은 문서 저장소를 활용하면 편리하게 저장할 수 있다.
* 키-값 저장소
    * 트라이는 아래 로직을 적용하면 해시 테이블 형태로 변환 가능하다.
        * 트라이에 보관된 모든 접두어를 해시 테이블 키로 변환
        * 각 트라이 노드에 보관된 모든 데이터를 해시 테이블 값으로 변환
            * ![](https://i.imgur.com/dUXMzJr.png)

위의 그림에서 각 트라이 노드는 하나의 <키, 값> 쌍으로 변환된다.

#### 질의 서비스

기존의 DB를 이용한 방식의 비효율성을 개선한 설계안이다.

![](https://i.imgur.com/ks8ghdO.png)

1. 검색 질의가 로드밸런서로 전송
2. 해당 질의를 API서버로 보낸다.
3. API서버는 트라이 캐시에서 데이터를 가져와 해당 요청에의 자동완성 검색어 제안 응답을 구성한다.
4. 데이터가 트라이 캐시에 없는 경우 DB에서 가져와 캐시에 채운다.
그래야 다음에 같은 접두어에 대한 질의가 오면 캐시에 보관된 데이터를 사용해 처리할 수 있다.
캐시 미스는 캐시 서버의 메모리가 부족하거나 캐시 서버에 장애가 있어도 발생 가능하다.

질의 서비스는 매우 빨라야 해서 추가적인 최적화 방안이 있다고 한다.

* AJAX요청
    * 웹 애플리케이션의 경우 보통 AJAX요청을 보내서 자동완성된 검색어 목록을 가져온다. 이 방법의 장점은 요청을 보내고 받기 위해 새로고침할 필요가 없다는 것이다. -> 비동기이므로
* 브라우저 캐싱
    * 대부분 애플리케이션의 경우 자동완성 검색어 제안 결과는 짧은 시간안에 자주 바뀌지 않는다. 따라서 제안된 검색어를 브라우저 캐시에 넣어두면 후속 질의의 결과는 해당 캐시에서 바로 가져갈 수 있다.
* 대규모 샘플링
    * 대규모 시스템의 경우, 모든 질의 결과를 로깅하도록 해 놓으면 CPU자원과 저장공간을 엄청나게 소진하게 된다. 이 때 데이터 샘플링을 쓰면 유용한데 N개 요청 가운데 1개만 로깅하도록 하는 것이다.
        * 로그처리할 1개의 요청은 어떻게 고르는지??

#### 트라이 연산

트라이는 검색어 자동완성 시스템의 핵심 컴포넌트다.
지금부터 트라이 관련 연산들이 어떻게 동작하는지 살펴보자

##### 트라이 생성

작업 서버가 담당하며, 데이터 분석 서비스의 로그나 DB로부터 취합된 데이터를 이용한다.

##### 트라이 갱신

트라이 갱신에는 두 가지 방법이 있다.

1. 매주 한 번 갱신하는 방법, 새로운 트라이를 만든 다음에 기존 트라이를 대체한다.
2. 트라이의 각 노드를 개별적으로 갱신하는 방법, 본 설계안에서는 이 방법을 채택하지 않는데, 성능이 좋지 않아서이다.
트라이가 적을 때에는 고려해볼만 하다.

##### 검색어 삭제

뭔가 있어서는 안되는 질의어는 자동완성 결과에서 제거해야 한다.
이 좋은 방법은 

![](https://i.imgur.com/7VRu0ZM.png)

이런 식으로 트라이 캐시 앞에 필터 계층을 두고 부적절한 질의어가 반환되지 않도록 하는 것이다.
필터 계층을 두면 필터 규칙에 따라 검색 결과를 자유롭게 변경할 수 있다는 장점이 있다.
DB에서 해당 검색어를 물리적으로 삭제하는 것은 다음번 업데이트 사이클에 비동기적으로 진행하면 된다.

#### 저장소 규모 확장

이제 트라이의 크기가 한 서버에 넣기에 너무 큰 경우 대응할 수 있도록 규모 확장성 문제를 해결해 본다.

일단 영어만 지원하면 되기 때문에 첫 글자를 기준으로 샤딩하는 방법을 생각할 수도 있다.
이 경우는 소문자 알파뱃 개수 26개로 최대 서버수가 제한되는데, 이 이상으로 서버 대수를 늘리려면 샤딩을 계층적으로 해야 한다.
이제 a로 시작하면서 또 거기서 26개의 개수에 대해 샤딩을 진행하는 것인데, c로 시작하는 단어가 x로 시작하는 단어보다 많을 테니 균등하게 배분되는것이 어려울 것이다.

이를 해결하기 위해서는 과거 질의 데이의 패턴을 분석하여 샤딩하는
![](https://i.imgur.com/rXtPV9d.png)
이런 방법을 제안한다.
검색어 대응 샤드 관리자는 어떤 검색어가 어느 저장소 서버에 저장되는지에 대한 정보를 관리한다.
예를 들어 's'로 시작하는 검색어의 양이 'u', 'v', 'w', 'x', 'y', 'z'로 시작하는 검색어를 전부 합친 것과 비슷하다면 저 두 분류들에의 샤드를 각각 하나씩만 배치하면 될것이다.

### 마무리

> Q: 다국어 지원이 가능하도록 시스템을 활장하려면?
> A: 트라이에 유니코드 데이터를 저장해야 한다.

유니코드는 고금을 막론하고 세상에 존재하는 모든 문제 체계를 지원하는 표준 인코딩 시스템이다.

> Q: 국가별로 인기 검색어 순위가 다르다면?
> A: 국가별로 다른 트라이를 사용하도록 한다. 트라이를 CDN에 저장하여 응답속도를 높이는 방법도 생각해볼 수 있다.

> Q: 실시간으로 변하는 검색어의 추이를 반영하려면?
> A: 뭔가 뉴스가 생겨서 특정 검색어의 인기가 갑자기 높아질 수도 있는데, 현 설계안은 그런 검색어 지원에 적합하지 않다.

1. 매주 한 번 씩만 작업 서버가 돌아서 시의 적절하게 트라이 갱신이 어렵다.
2. 때맞춰서 서버가 실행된다 해도 트라이 구성에 시간이 너무 오래 걸린다.

실시간 검색어 자동완성 서비스에 쓰이는 몇 가지 아이디어를 살펴본다.

* 샤딩을 통해 작업 대상 데이터의 양을 줄인다.
* 순위 모델을 바꾸어 최근 검색어에 보다 높은 가중치를 주도록 한다.
* 데이터가 스트림 형태로 올 수 있다는 점, 즉 한번에 모든 데이터를 동시에 사용할 수 없는 가능성이 있다는 점을 고려해야 한다. 데이터가 스트링밍된다는 것은 데이터가 지속적으로 생성된다는 것이다.
    * 아파치 하둡 맵리듀스
    * 아파치 스파크 스트리밍
    * 아파치 스톰
    * 아파치 카프카
    * 등등
        * 얘들이 그런 부류의 시스템이다.
